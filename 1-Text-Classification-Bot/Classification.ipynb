{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IERG4080 Assignment 1\n",
    "\n",
    "**Text Classification and Telegram Bot**\n",
    "\n",
    "Wentao Zhu 1155123308@link.cuhk.edu.hk\n",
    "\n",
    "[Instructions](https://iems5780.github.io/1819t1/assignments/assignment-1.html)\n",
    "\n",
    "## Task 1: Text Classification \n",
    "\n",
    "### 1. Data Preparation\n",
    "\n",
    "Notation:\n",
    "- True = Positive\n",
    "- False = Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-16 14:44:10--  http://!wget/\n",
      "Resolving !wget (!wget)... failed: Name or service not known.\n",
      "wget: unable to resolve host address '!wget'\n",
      "--2018-10-16 14:44:10--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: 'aclImdb_v1.tar.gz'\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  6.49MB/s    in 12s     \n",
      "\n",
      "2018-10-16 14:44:22 (6.67 MB/s) - 'aclImdb_v1.tar.gz' saved [84125825/84125825]\n",
      "\n",
      "FINISHED --2018-10-16 14:44:22--\n",
      "Total wall clock time: 12s\n",
      "Downloaded: 1 files, 80M in 12s (6.67 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget !wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/test/neg/ 12500\n",
      "aclImdb/train/neg/ 12500\n",
      "aclImdb/test/pos/ 12500\n",
      "aclImdb/train/pos/ 12500\n"
     ]
    }
   ],
   "source": [
    "paths = ['aclImdb/test/neg/','aclImdb/train/neg/','aclImdb/test/pos/','aclImdb/train/pos/']\n",
    "for idx,file_path in enumerate(paths):\n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "        print(file_path, len(files))\n",
    "        for file in files:\n",
    "            shutil.move(file_path+file, 'data/'+str(idx)+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPositive(ss):\n",
    "    rating = int(ss.split('_')[1].split('.')[0])\n",
    "#     print(rating)\n",
    "    if rating>5:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataset is now under data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data/train')\n",
    "os.mkdir('data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Positive: 17587/35000 = 0.5024857142857143\n",
      "Test Positive: 7413/15000 = 0.4942\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('data/', topdown=False):\n",
    "    num_files = len(files)\n",
    "    fileset = set(files)\n",
    "    new_train = set(random.sample(fileset, int(num_files*0.7)))\n",
    "    new_test = fileset - new_train\n",
    "    pos_in_train = 0 \n",
    "    pos_in_test = 0\n",
    "    for train_file in new_train:\n",
    "        pos_in_train += isPositive(train_file)\n",
    "        shutil.move('data/'+train_file, 'data/train/'+train_file)\n",
    "    for test_file in new_test:\n",
    "        pos_in_test += isPositive(test_file)\n",
    "        shutil.move('data/'+test_file, 'data/test/'+test_file)\n",
    "print('Train Positive: {}/{} = {}'.format(pos_in_train, len(new_train), pos_in_train/len(new_train)))\n",
    "print('Test Positive: {}/{} = {}'.format(pos_in_test, len(new_test), pos_in_test/len(new_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorvization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "y = [] # Ground Truth\n",
    "for root, dirs, files in os.walk('data/train'):\n",
    "    for train_file in files:\n",
    "        y.append(isPositive(train_file))\n",
    "        f = io.open('data/train/' + train_file, mode=\"r\", encoding=\"utf-8\")\n",
    "        texts.append(f.read())\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfvectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(texts)\n",
    "x_tf = tfvectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_test = []\n",
    "y_test = [] # Ground Truth\n",
    "for root, dirs, files in os.walk('data/test'):\n",
    "    for test_file in files:\n",
    "        y_test.append(isPositive(test_file))\n",
    "        f = io.open('data/test/' + test_file, mode=\"r\", encoding=\"utf-8\")\n",
    "        texts_test.append(f.read())\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorizer.transform(texts_test)\n",
    "x_test_tf = tfvectorizer.transform(texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes = MultinomialNB().fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = naiveBayes.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.83      0.88      0.86      7587\n",
      "       True       0.87      0.82      0.84      7413\n",
      "\n",
      "avg / total       0.85      0.85      0.85     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8504666666666667"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_nb = sum(y_test==y_predict)/len(y_predict)\n",
    "accuracy_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now use TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes_tf = MultinomialNB().fit(x_tf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.85      0.88      0.87      7587\n",
      "       True       0.88      0.85      0.86      7413\n",
      "\n",
      "avg / total       0.87      0.86      0.86     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8648666666666667"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_tf = naiveBayes_tf.predict(x_test_tf)\n",
    "print(classification_report(y_test, y_predict_tf))\n",
    "accuracy_nb_tf = sum(y_test==y_predict_tf)/len(y_test)\n",
    "accuracy_nb_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logis = LogisticRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.88      0.89      7587\n",
      "       True       0.88      0.89      0.89      7413\n",
      "\n",
      "avg / total       0.89      0.89      0.89     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8872"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_logis = logis.predict(x_test)\n",
    "print(classification_report(y_test, y_predict_logis))\n",
    "accuracy_logi = sum(y_test==y_predict_logis)/len(y_test)\n",
    "accuracy_logi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.89      0.90      7587\n",
      "       True       0.89      0.91      0.90      7413\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8962"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logis_tf = LogisticRegression().fit(x_tf, y)\n",
    "y_predict_logis_tf = logis_tf.predict(x_test_tf)\n",
    "print(classification_report(y_test, y_predict_logis_tf))\n",
    "accuracy_logi_tf = sum(y_test==y_predict_logis_tf)/len(y_test)\n",
    "accuracy_logi_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Adding Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerB = CountVectorizer(ngram_range=(1, 2))\n",
    "tfvectorizerB = TfidfVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizerB.fit_transform(texts)\n",
    "x_tf = tfvectorizerB.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorizerB.transform(texts_test)\n",
    "x_test_tf = tfvectorizerB.transform(texts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes with Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.88      0.89      0.88      7587\n",
      "       True       0.89      0.87      0.88      7413\n",
      "\n",
      "avg / total       0.88      0.88      0.88     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8822666666666666"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayes = MultinomialNB().fit(x,y)\n",
    "y_predict = naiveBayes.predict(x_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "accuracy_nb = sum(y_test==y_predict)/len(y_predict)\n",
    "accuracy_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.89      0.90      0.89      7587\n",
      "       True       0.90      0.88      0.89      7413\n",
      "\n",
      "avg / total       0.89      0.89      0.89     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8907333333333334"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayes_tf = MultinomialNB().fit(x_tf, y)\n",
    "y_predict_tf = naiveBayes_tf.predict(x_test_tf)\n",
    "print(classification_report(y_test, y_predict_tf))\n",
    "accuracy_nb_tf = sum(y_test==y_predict_tf)/len(y_test)\n",
    "accuracy_nb_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.90      0.91      7587\n",
      "       True       0.90      0.92      0.91      7413\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9088"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logis = LogisticRegression().fit(x, y)\n",
    "y_predict_logis = logis.predict(x_test)\n",
    "print(classification_report(y_test, y_predict_logis))\n",
    "accuracy_logi = sum(y_test==y_predict_logis)/len(y_test)\n",
    "accuracy_logi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.91      0.88      0.90      7587\n",
      "       True       0.88      0.91      0.90      7413\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8982"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logis_tf = LogisticRegression().fit(x_tf, y)\n",
    "y_predict_logis_tf = logis_tf.predict(x_test_tf)\n",
    "print(classification_report(y_test, y_predict_logis_tf))\n",
    "accuracy_logi_tf = sum(y_test==y_predict_logis_tf)/len(y_test)\n",
    "accuracy_logi_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import train_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_for_fr = open('ft_train.txt','w', encoding=\"utf-8\") \n",
    "for (idx,item) in enumerate(texts):\n",
    "    line = ('__label__'+str(y[idx])+' '+item+'\\n')\n",
    "    file_for_fr.write(line)\n",
    "file_for_fr.close()\n",
    "\n",
    "file_for_fr = open('ft_test.txt','w', encoding=\"utf-8\") \n",
    "for (idx,item) in enumerate(texts_test):\n",
    "    line = ('__label__'+str(y_test[idx])+' '+item+'\\n')\n",
    "    file_for_fr.write(line)\n",
    "file_for_fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t15000\n",
      "P@1\t0.875\n",
      "R@1\t0.875\n"
     ]
    }
   ],
   "source": [
    "model = train_supervised(input='ft_train.txt')\n",
    "print_results(*model.test('ft_test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 0.8745333333333334, 0.8745333333333334)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test('ft_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Persistence\n",
    "\n",
    "The best model in terms of the accuracy is **Logistic Regression with Bi-grams and CounterVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump([vectorizerB,logis], 'model.pkl') # Transformer and Model are both needed for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
